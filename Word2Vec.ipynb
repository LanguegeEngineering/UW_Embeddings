{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Moduły"
      ],
      "metadata": {
        "id": "Uopu_5-Idtjz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJsGu7d2AcPF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Przykład losowych wektorow"
      ],
      "metadata": {
        "id": "91bbRJurdsv0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btcjnvBdj50N"
      },
      "source": [
        "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
        "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
        "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
        "hello_embed = embeds(lookup_tensor)\n",
        "print(hello_embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tworzenie wektorow dla krotkiego tekstu"
      ],
      "metadata": {
        "id": "shipApdUd8zE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4FFduqaPZQ1"
      },
      "source": [
        "def make_context_vector(context, word_to_id):\n",
        "    \"\"\"\n",
        "    Stworzenie tensora z indeksami dla calego kontekstu\n",
        "    \"\"\"\n",
        "    idxs = [word_to_id[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHTzrhOpPZO-"
      },
      "source": [
        "def get_index_of_max(input):\n",
        "    index = 0\n",
        "    for i in range(1, len(input)):\n",
        "        if input[i] > input[index]:\n",
        "            index = i\n",
        "    return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro_B0OXsPZNK"
      },
      "source": [
        "def get_max_prob_result(input, id_to_word):\n",
        "    return id_to_word[get_index_of_max(input)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BVxCCqrPZLA"
      },
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "EMDEDDING_DIM = 100\n",
        "\n",
        "word_to_id = {}\n",
        "id_to_word = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxyvahWpPZHx"
      },
      "source": [
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT2qOOHYPZFl"
      },
      "source": [
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "print(vocab)\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAtyrwPaPZBR"
      },
      "source": [
        "for i, word in enumerate(vocab):\n",
        "    word_to_id[word] = i\n",
        "    id_to_word[i] = word\n",
        "\n",
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:5])"
      ],
      "metadata": {
        "id": "AEhdQTwderEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXNriRlwPzrY"
      },
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "        \n",
        "        #out: 1 x vocab_size\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.LongTensor([word_to_id[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NaV2Fu_P1ti"
      },
      "source": [
        "model = CBOW(vocab_size, EMDEDDING_DIM)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []"
      ],
      "metadata": {
        "id": "YUs84H82frQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnOIuer8P4FN"
      },
      "source": [
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_id) \n",
        "        #print(context_vector)\n",
        "        #print(word_to_id[target])\n",
        "        model.zero_grad()\n",
        "        log_probs = model(context_vector)\n",
        "        #print(log_probs)\n",
        "        loss = loss_function(log_probs, torch.tensor([word_to_id[target]], dtype=torch.long))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "        total_loss += loss.data\n",
        "    loss_list.append(total_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3eXAu-6kBKz"
      },
      "source": [
        "# TEST\n",
        "context = ['about', 'process', 'inhabit', 'directed']\n",
        "context_vector = make_context_vector(context, word_to_id)\n",
        "result = model(context_vector).data.numpy()\n",
        "print('Raw text: {}\\n'.format(' '.join(raw_text)))\n",
        "print('Context: {}\\n'.format(context))\n",
        "print('Prediction: {}'.format(get_max_prob_result(result[0], id_to_word)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9HKKRXWQEVn"
      },
      "source": [
        "### Zadania\n",
        "\n",
        "1. Wyrysować wykresy straty, pobawić się parametrami\n",
        "2. Zmienić dane tekstowe na polski\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNLaqfI7QBdp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}